---
title: "[NLP] FiQA ABSA(진행중)"
layout: post
tags:
- NLP
- SentimentAnalysis
- ABSA
- Ongoing
categories:
- FinancialDomainLM
- NLP
---

## ABSA
Aspect Based Sentiment Analysis

예를 들어 “I hated their fajitas, but their salads were great” 라는 문장이 있을 때 앞 문장은 부정적이고 뒷 문장은 긍정적인 것을 알 수 있다.
원래의 Sentiment Analysis는 서로 다른 극성을 가진 전체 문장에 대해 감정분석을 하게 되어 문제가 생길 수 있다.
하지만 ABSA(Aspect Based Sentiment Analysis)의 경우 'fajitas'와 'salads'에 대해 각각의 감정분석을 할 수 있다.

ABSA는 크게 두 가지 방법으로 할 수 있다.
1. NLI
2. QA

**NLI**
```
 [CLS] + 전제 + [SEP] + 가설 + [SEP]
```
**QA**
```
[CLS] + 질문 + [SEP] + 지문 + [SEP]
```

### ABSA 방법
[Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence](https://arxiv.org/pdf/1903.09588.pdf) 논문에서는 NLI-M, NLI-B, QA-M, QA-B 총 4가지 방법을 소개하고 있다.
또한 target(term)과 aspect을 함께 넣는다.


NLI-M, QA-M의 결과로는 sentiment polarity로 나오고 NLI-B, QA-B의 경우 {yes, no}의 두 가지 classification으로 결과가 나온다
![ABSA output](https://d3i71xaburhd42.cloudfront.net/0de47f354468283efc7765ec0b3588b2ae483c77/2-Table2-1.png)
#### 1. NLI-M
```
[CLS] I hated their fajitas, but ther salads were greate [SEP] fajitas [SEP] # without aspect
[CLS] I hated their fajitas, but ther salads were greate [SEP] food quality - fajitas [SEP] # with aspect
```

#### 2. NLI-B
```
[CLS] I hated their fajitas, but ther salads were greate [SEP] food quality - fajitas - positive [SEP] # with aspect
```

#### 3. QA-M
```
[CLS] I hated their fajitas, but ther salads were greate [SEP] “what do you think of fajitas [SEP] # without aspect
[CLS] I hated their fajitas, but ther salads were greate [SEP] “what do you think of food quality - fajitas [SEP] # with aspect
```

#### 4. QA-B
```
[CLS] I hated their fajitas, but ther salads were greate [SEP] the polarity of the aspect food quality of fajitas is positive [SEP] # with aspect
```

#### 선택한 방법
ABSA 성능을 올리는 것이 목표가 아니기 때문에 간단히 구현할 수 있는 **NLI-M** 방식을 채용하였다.

## FiQA
- 금융 분야의 마이크로블로그(블로거가 올린 한 두 문장 정도 분량의 단편적 정보) 메시지, 뉴스 보도자료나 헤드라인이 영어로 주어진다.
- 텍스트에 사전에 정의한 aspect class 목록에서 멘션된 target aspect를 찾고, 멘션된 target의 각 감정 점수를 예측한다.
- 감정 점수는 -1(부정)에서 1(긍정)까지의 연속된 수로 되어 있다.

```json
"14902": {
    "sentence": "$TZOO a close above 28.64 and we are ready to rock and roll",
    "info": [
      {
        "snippets": "['a close above 28.64 and we are ready to rock and roll']",
        "sentiment_score": "0.308",
        "target": "TZOO",
        "aspects": "['Stock/Price Action/Bullish']"
      }
    ]
  },
```


FiQA는 headline과 post데이터가 각각 존재한다.
### Headline
- 데이터가 깨끗한 편
- `"sentence"`의  `"target"`앞에 $가 붙지 않음

### Post
- 데이터에 특수문자나 "loooooooooongggggg"과 같이 강조를 위한 늘임 단어 등이 있음
- `"sentence"`의 `"target"`앞에 $가 붙음

### Cleansing
- `"sentence"`의 `"target"` 앞 $를 삭제
- @ 삭제
- 연속된 온점 하나의 온점으로 바꿈 ("..." -> ".")
- 연속된 띄어쓰기 하나의 띄어쓰기로 바꿈("   " -> " ")

### Input
```
[CLS] "TZOO a close above 28.64 and we are ready to rock and roll" [SEP] TZOO [SEP]
```


## Papers & Experiments
[FinBERT: A Pretrained Language Model for Financial Communications (**Yi Yang, 2020**)](https://arxiv.org/pdf/2006.08097.pdf) 논문에서 FiQA score를 -1, 0, 1로 3 classes classification으로 바꾸어 측정했기 때문에 R2에 대한 정보를 몰라 [Yi Yang FinBERT Github](https://github.com/yya518/FinBERT)을 참고하여 해당 모델 또한 R2 score를 측정하였다.

그 외의 논문들([FinBERT : A Pre-trained Financial Language Representation Model for Financial Text Mining (**Zhuang Liu, 2021**)](https://www.ijcai.org/proceedings/2020/0622.pdf), [FinBERT : Financial Sentiment Analysis with Pre-trained Language Models (**Dogu Tan Araci, 2019**)](https://arxiv.org/pdf/1908.10063.pdf))의 경우 구현한 모델을 구할 수 없고 자세한 hyper-parameters에 대해 설명하지 않았다.

### Code
[FiQA Github](https://github.com/deep-over/Financial-Pre-trained-research/tree/main/downstream/SA/FiQA)
### Hyper-Parameters
- epochs : 20
- max_length : 128
- batch_size : 64
- learning_rate : 2e-5
- lr_scheduler : none (코드 상엔 있지만 실제로는 사용 안 함)

FiQA 데이터가 워낙 적어 학습이 잘 안 되어 epoch을 20으로 하여 돌렸다.

### Result

Financial Domain 사전학습 모델이 아직 전부 학습되지 않아 기존 base 모델 결과만 첨부한다.
#### Paper FiQA Headline/Post Result
Dogu의 논문은 Headline/Post 결과를 따로 내지 않은 것 같다.

|Dataset | Model | MSE Loss | R2 |
| -------- | -------- | -------- | -------- |
| Headline | Zhuang Base | 0.29 | 0.67 |
| Post | Zhuang Base | 0.28 | 0.26 |

#### Without ABSA Headline

| Model | MSE Loss | R2 |
| -------- | -------- | -------- |
| roberta-base | 0.033 | 0.796 |
| facebook/bart-base | 0.106 | 0.354 |
| yiyanghkust/finbert-tone | 0.064 | 0.605 |

#### Headline

| Model | MSE Loss | R2 |
| -------- | -------- | -------- |
| roberta-base | 0.035 | 0.785 |
| facebook/bart-base | 0.079 | 0.523 |
| yiyanghkust/finbert-tone | 0.066 | 0.594 |
| ours | None | None |

#### Without ABSA Post

| Model | MSE Loss | R2 |
| -------- | -------- | -------- |
| roberta-base | 0.05 | 0.708 |
| facebook/bart-base | 0.092 | 0.468 |
| yiyanghkust/finbert-tone | 0.086 | 0.508 |

#### Post

| Model | MSE Loss | R2 |
| -------- | -------- | -------- |
| roberta-base | 0.042 | 0.762 |
| facebook/bart-base | 0.081 | 0.544 |
| yiyanghkust/finbert-tone | 0.059 | 0.663 |
| ours | None | None |


------

### Conclusion
Headline은 Post에 비해 데이터가 훨씬 간결하고 Target이 문장에 하나씩만 있어 ABSA 적용했을 때 큰 차이가 보이지 않는 것 같다.

이에 비해 Target으로 추정되는 것이 한 문장에 여러 개 나오는 것으로 보이는 Post의 경우 ABSA를 적용했을 때 많은 성능 향상을 보였다.

추후에 연구실에서 학습하는 Financial Domain Pre-trained Language Model에 ABSA Fine-tuning을 적용하여 결과 확인할 예정이다.


## References
- [ASPECT BASED SENTIMENT ANALYSIS](http://nlp.cs.aueb.gr/theses/ipavlopoulos-thesis.pdf)
- [Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence](https://arxiv.org/pdf/1903.09588.pdf)
- [QA](https://ratsgo.github.io/nlpbook/docs/qa/overview/)
- [NLI](https://ratsgo.github.io/nlpbook/docs/pair_cls/overview/)
- [FinBERT : A Pre-trained Financial Language Representation Model for Financial Text Mining (**Zhuang Liu, 2021**)](https://www.ijcai.org/proceedings/2020/0622.pdf)
- [FinBERT : Financial Sentiment Analysis with Pre-trained Language Models (**Dogu Tan Araci, 2019**)](https://arxiv.org/pdf/1908.10063.pdf)
- [FinBERT: A Pretrained Language Model for Financial Communications (**Yi Yang, 2020**)](https://arxiv.org/pdf/2006.08097.pdf)
- [Yi Yang FinBERT Github](https://github.com/yya518/FinBERT)
